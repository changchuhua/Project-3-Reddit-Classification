{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- [Imports](#import)\n",
    "- [Further Cleaning](#clean)\n",
    "- [Splitting and Vectorizing](#splitvect)\n",
    "- [Baseline Model](#model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Imports<a id=import></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned=pd.read_csv(r'..\\datasets\\cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how to excel in a physics undergraduate degree...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why do shorter wavelength form better images?i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to solve for maximum compression in a spri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>practice exam questioni have this question  a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lagrangian mechanics and generalized forcesso ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  subreddit\n",
       "0  how to excel in a physics undergraduate degree...          1\n",
       "1  why do shorter wavelength form better images?i...          1\n",
       "2  how to solve for maximum compression in a spri...          1\n",
       "3  practice exam questioni have this question  a ...          1\n",
       "4  lagrangian mechanics and generalized forcesso ...          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>speed of the trucka truck started from town a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>factor questionhi, i'm trying to brush up on m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>how to calculate the mean ? is there better wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>can anyone tell me what will be the sales ratio?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>drop chanceso i'm currently playing a game tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  subreddit\n",
       "1987  speed of the trucka truck started from town a ...          0\n",
       "1988  factor questionhi, i'm trying to brush up on m...          0\n",
       "1989  how to calculate the mean ? is there better wa...          0\n",
       "1990   can anyone tell me what will be the sales ratio?          0\n",
       "1991  drop chanceso i'm currently playing a game tha...          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the data we imported\n",
    "display(cleaned.head())\n",
    "display(cleaned.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Further Cleaning<a id=clean></a>\n",
    "Before we create our baseline model, we perform further cleaning by removing stopwords, numeric characters and punctuation from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "cleaned['stoptext'] = cleaned['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all numeric characters\n",
    "cleaned['stoptext'] = cleaned['stoptext'].str.replace('\\d+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all punctuation\n",
    "cleaned['stoptext'] = cleaned['stoptext'].str.replace(r'[^\\s\\w]+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'does pressure in a sealed container rise as it ascends in altitude?the source of this discussion is talking about inflating an inflatable stand up paddleboard at lower altitude and then driving it up to a mountain lake. these paddle boards have a stiff strong structure that holds their shape. they are designed to hold aprox. 15psi. if someone was to fill the paddleboard to 15psi say at 4,000ft altitude, then drive it to a mountain lake at say 8,000ft altitude, will the pressure in the paddleboard change from the change in altitude or is 15psi in a container, 15psi regardless of ambient pressure?'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check original text\n",
    "cleaned.text[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pressure sealed container rise ascends altitude the source discussion talking inflating inflatable stand paddleboard lower altitude driving mountain lake  paddle boards stiff strong structure holds shape  designed hold aprox   psi  someone fill paddleboard  psi say    ft altitude  drive mountain lake say    ft altitude  pressure paddleboard change change altitude  psi container   psi regardless ambient pressure '"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check cleaned text\n",
    "cleaned.stoptext[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that our cleaning has been performed successfully.<br/>\n",
    "Next, we lemmatize our words to prevent repetition of different word variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned['stoptext'] = cleaned['stoptext'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pressure sealed container rise ascends altitude the source discussion talking inflating inflatable stand paddleboard lower altitude driving mountain lake paddle board stiff strong structure hold shape designed hold aprox psi someone fill paddleboard psi say ft altitude drive mountain lake say ft altitude pressure paddleboard change change altitude psi container psi regardless ambient pressure'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.stoptext[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that our lemmatizer has worked as the word 'holds' in our original text has been lemmatized to 'hold'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Splitting and Vectorizing<a id=splitvect></a>\n",
    "Next, we perform our train-test-split and count vectorize on our data before we create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(cleaned.stoptext,cleaned.subreddit,random_state=42,stratify=cleaned.subreddit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if our data has been stratified properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    748\n",
      "1    746\n",
      "Name: subreddit, dtype: int64\n",
      "0    250\n",
      "1    248\n",
      "Name: subreddit, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we next perform our vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english',strip_accents='unicode')\n",
    "X_train=pd.DataFrame(cvec.fit_transform(X_train).todense(),columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1494 entries, 0 to 1493\n",
      "Columns: 7236 entries, 4ρ4φ to τy\n",
      "dtypes: int64(7236)\n",
      "memory usage: 82.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our corpus has been vectorized into 7236 features.<br/>\n",
    "Let us analyze which words appear the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amp         649\n",
      "question    508\n",
      "time        410\n",
      "know        396\n",
      "help        396\n",
      "like        334\n",
      "problem     321\n",
      "answer      313\n",
      "number      305\n",
      "physic      294\n",
      "force       282\n",
      "need        252\n",
      "equation    248\n",
      "energy      246\n",
      "point       227\n",
      "way         209\n",
      "say         204\n",
      "ve          196\n",
      "work        196\n",
      "speed       192\n",
      "dtype: int64\n",
      "maxed               1\n",
      "matteri             1\n",
      "matterhi            1\n",
      "matlab              1\n",
      "market              1\n",
      "maththere           1\n",
      "mathing             1\n",
      "mathgiven           1\n",
      "mathemathics        1\n",
      "mathemagicians      1\n",
      "mathconsumer        1\n",
      "mathcal             1\n",
      "mathbb              1\n",
      "matched             1\n",
      "masteringphysics    1\n",
      "martingale          1\n",
      "martial             1\n",
      "marpocky            1\n",
      "markup              1\n",
      "4ρ4φ                1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Which words appear the most?\n",
    "word_counts = X_train.sum(axis=0)\n",
    "print(word_counts.sort_values(ascending = False).head(20))\n",
    "print(word_counts.sort_values(ascending = False).tail(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the most recurring words are basic terms like question or time or know or help.<br/>\n",
    "The amp term is interesting and through manual observation of our data, it might likely be an encoding artifact left from our scraping process.<br/>\n",
    "Let us analyze the most recurring terms in each of our subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in AskPhysics:\n",
      "answer          313\n",
      "correct         121\n",
      "change           90\n",
      "acceleration     88\n",
      "bit              86\n",
      "charge           75\n",
      "book             75\n",
      "average          73\n",
      "class            71\n",
      "case             68\n",
      "appreciated      64\n",
      "assume           62\n",
      "course           59\n",
      "chance           57\n",
      "black            49\n",
      "calculus         46\n",
      "approach         46\n",
      "certain          46\n",
      "card             45\n",
      "basic            42\n",
      "dtype: int64\n",
      "Most common words in askmath:\n",
      "amp            649\n",
      "ball           174\n",
      "calculate      115\n",
      "angle           95\n",
      "come            87\n",
      "able            83\n",
      "constant        82\n",
      "algebra         78\n",
      "air             77\n",
      "area            69\n",
      "advance         64\n",
      "actually        62\n",
      "cm              54\n",
      "based           49\n",
      "confused        49\n",
      "calculation     48\n",
      "best            46\n",
      "center          40\n",
      "axis            39\n",
      "concept         38\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Most common words in AskPhysics:')\n",
    "print(X_train.loc[:,(pd.DataFrame(y_train)==1).subreddit.tolist()].sum(axis=0).sort_values(ascending=False).head(20))\n",
    "print('Most common words in askmath:')\n",
    "print(X_train.loc[:,(pd.DataFrame(y_train)==0).subreddit.tolist()].sum(axis=0).sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking for the most recurring words in our specific subreddits, it seems that more topic-specific terms appear.<br/>\n",
    "In AskPhysics, two topic-specific highly recurring words are acceleration and charge. We can infer that there are substantial posts in this subreddit discussing kinematics and electromagnetic questions.<br/>\n",
    "In askmath, two topic-specific highly recurring words are ball and angle. Ball-based questions in math are normally either related to kinematics (similar to physics), or statistics and probability. Angle being a recurring word implies that many posts are seeking trigonometric help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Baseline Model<a id=model></a>\n",
    "Finally, we are ready to create our baseline model.<br/>\n",
    "We start by making our X_test split into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.DataFrame(cvec.transform(X_test).todense(),columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 498 entries, 0 to 497\n",
      "Columns: 7236 entries, 4ρ4φ to τy\n",
      "dtypes: int64(7236)\n",
      "memory usage: 27.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our baseline model, we will utilize the reliable Logistic Regression classifier with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.893574297188755"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a mean accuracy of 89.4% from our baseline model, which is quite impressive as a start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8893528183716075"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=logreg.predict(X_test)\n",
    "f1_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate our f1 score that indicates the balance between our predicted and true positive rates.<br/>\n",
    "We will use this as our main metric for scoring all future models.<br/>\n",
    "\n",
    "In the next section, we will investigate how we may improve our model and create an optimal model to use as our final classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
